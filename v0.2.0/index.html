<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Introduction · RedClust.jl</title><script data-outdated-warner src="assets/warner.js"></script><link rel="canonical" href="https://abhinavnatarajan.github.io/RedClust.jl/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>RedClust.jl</a></span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Introduction</a><ul class="internal"><li><a class="tocitem" href="#Installation"><span>Installation</span></a></li><li><a class="tocitem" href="#Basic-example"><span>Basic example</span></a></li><li><a class="tocitem" href="#Model"><span>Model</span></a></li><li><a class="tocitem" href="#Point-estimation"><span>Point estimation</span></a></li><li><a class="tocitem" href="#Citing-this-package"><span>Citing this package</span></a></li><li><a class="tocitem" href="#Bibliography"><span>Bibliography</span></a></li></ul></li><li><a class="tocitem" href="reference/">Reference</a></li><li><a class="tocitem" href="changelog/">Changelog</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Introduction</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Introduction</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/abhinavnatarajan/RedClust.jl/blob/main/docs/src/index.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Introduction"><a class="docs-heading-anchor" href="#Introduction">Introduction</a><a id="Introduction-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction" title="Permalink"></a></h1><p><a href="https://github.com/abhinavnatarajan/RedClust.jl">RedClust</a> is a <a href="https://julialang.org/">Julia</a> package for Bayesian clustering of high-dimensional Euclidean data using pairwise dissimilarity information instead of the raw observations. It uses an MCMC sampler to generate posterior samples from the space of all possible clustering structures on the data. </p><h2 id="Installation"><a class="docs-heading-anchor" href="#Installation">Installation</a><a id="Installation-1"></a><a class="docs-heading-anchor-permalink" href="#Installation" title="Permalink"></a></h2><p>The package can be installed by typing <code>]add RedClust</code> into the Julia REPL or by the usual method:</p><pre><code class="language-julia hljs">using Pkg
Pkg.add(&quot;RedClust&quot;)</code></pre><p>RedClust also requires <a href="https://www.r-project.org/"><code>R</code></a> and the R package <a href="https://CRAN.R-project.org/package=salso"><code>salso</code></a>. If R is already installed, make sure the <code>R_HOME</code> environment variable is set to the R home directory (you could run <code>R.home()</code> in R to determine the location of this directory). If R or <code>salso</code> are not found, they are automatically installed during package installation.  </p><h2 id="Basic-example"><a class="docs-heading-anchor" href="#Basic-example">Basic example</a><a id="Basic-example-1"></a><a class="docs-heading-anchor-permalink" href="#Basic-example" title="Permalink"></a></h2><pre><code class="language-julia hljs">using RedClust
# Generate data
points, distM, clusts, probs, oracle_coclustering = 
	generatemixture(N, K; α = 10, σ = data_σ, dim = data_dim)
# Let RedClust choose the best prior hyperparameters
params = fitprior(pnts, &quot;k-means&quot;, false)
# Set the MCMC options
options = MCMCOptionsList(numiters = 5000)
data = MCMCData(points)
# Run the sampler
result = runsampler(data, options, params)
# Get a point estimate 
pointestimate, index = getpointestimate(result)
# Summary of MCMC and point estimate
summarise(result)
summarise(pointestimate, clusts)</code></pre><h2 id="Model"><a class="docs-heading-anchor" href="#Model">Model</a><a id="Model-1"></a><a class="docs-heading-anchor-permalink" href="#Model" title="Permalink"></a></h2><p>RedClust implements the model described in Natarajan et al. (2022). The key features are-</p><ol><li>The use of a random partition model with an unknown number of clusters <span>$K$</span> which allows for posterior inference on <span>$K$</span>. That is, there is a prior distribution on the space of all possible clustering structures with any number of clusters from one to the number of observations. The number of clusters is an object of inference to be determined by MCMC sampling. </li><li>The pairwise dissimilarities between observations are assumed to be mutually independent given the clustering assignment; that is, the clustering likelihood is a <em>composite</em> or <em>pseduo-likelihood</em>. </li><li>The clustering likelihood is comprised of a <em>cohesive</em> part and a <em>repulsive</em> part. The repulsive component of the likelihood imposes a strong identifiability constraint on the clustering; clusters must not only comprise points that have similar small distances among themselves, but also similar distances to points in other clusters.</li></ol><p>The prior on the clustering structure can be chosen according to application in question. The current version of RedClust implements a <em>microclustering</em> prior (<a href="#miller">Miller et al., 2015</a>; <a href="#betancourt">Betancourt et al., 2022</a>). This means that the partition is generated by drawing cluster sizes <span>$n_1, \ldots, n_K$</span> from a random distribution <span>$\nu$</span> (conditional upon <span>$n_1 + \ldots n_K = n$</span> where <span>$n$</span> is the number of observations), and cluster labels are given by a uniform random permutation of </p><p class="math-container">\[\underbrace{1, \ldots, 1}_{n_1 \text{ times}}, \ldots, \underbrace{K, \ldots, K}_{n_K \text{ times}}\]</p><p>RedClust implements a microclustering prior with <span>$\nu$</span> a shifted negative binomial with random parameters <span>$r$</span> and <span>$p$</span>, which are sampled from a Gamma and Beta distribution respectively.</p><p class="math-container">\[\begin{align*}
r &amp;\sim \mathrm{Gamma}(\eta, \sigma)\\
p &amp;\sim \mathrm{Beta}(u, v)
\end{align*}\]</p><p>This results in the following partition prior: </p><p class="math-container">\[\pi(\rho_n \mid r, p) \propto K! p^{n-K}(1-p)^{rK}\Gamma(r)^{-K}\prod_{k=1}^K n_k \Gamma(n_k+r-1)\]</p><p>where <span>$\rho_n$</span> is the partition and <span>$K$</span> is the number of clusters in the partition. The partition likelihood is given by</p><p class="math-container">\[\begin{align*}
\lambda_k &amp;\overset{\mathrm{iid}}{\sim} \mathrm{Gamma}(\alpha, \beta), \quad 1 \leq k \leq K\\
\theta_{kt} &amp;\overset{\mathrm{iid}}{\sim} \mathrm{Gamma}(\zeta, \gamma), \quad 1 \leq k &lt; t \leq K
\end{align*}\]</p><p class="math-container">\[\pi(D, \mid \rho_n, \boldsymbol{\lambda}, \boldsymbol{\theta}, r, p) = \left[ \prod_{k=1}^K \prod_{\substack{i, j \in C_k \\ i \neq j}} \frac{D_{ij}^{\delta_1 - 1}\lambda_k^{\delta_1}}{\Gamma(\delta_1)} \exp(-\lambda_k D_{ij}) \right] \left[\prod_{\substack{t, k = 1 \\ t \neq K}} \prod_{\substack{i \in C_k \\ j \in C_t}} \frac{D_{ij}^{\delta_2-1}\theta_{kt}^{\delta_2}}{\Gamma(\delta_2)} \exp(-\theta_{kt}D_{ij}) \right]\]</p><p>where <span>$\boldsymbol D$</span> is the matrix of pairwise dissimilarities between observations.</p><h2 id="Point-estimation"><a class="docs-heading-anchor" href="#Point-estimation">Point estimation</a><a id="Point-estimation-1"></a><a class="docs-heading-anchor-permalink" href="#Point-estimation" title="Permalink"></a></h2><p>A clustering point-estimate <span>$\boldsymbol c^*$</span> can be determined in a number of ways. </p><ol><li>Choosing the sample with maximum likelihood or maximum posterior. This corresponds to an MLE or MAP estimate using the MCMC samples as an approximation to the likelihood and posterior.</li><li>Searching for a clustering that minimises the posterior expectation of a loss function <span>$\ell$</span> such as the Binder loss (<a href="#binder">Binder, 1978</a>), the Variation of Information distance (<a href="#meila">Meilă, 2007</a>; <a href="#wade">Wade and Ghahramani, 2018</a>), or the Normalised Information Distance (<a href="#kraskov">Kraskov et al., 2005</a>). That is, </li></ol><p class="math-container">\[\boldsymbol c^* = \argmin_{\boldsymbol c} \mathbb{E}_{\boldsymbol c&#39;}[\ell(\boldsymbol c, \boldsymbol c&#39;)]\]</p><ol><li>A naive method is to restrict the search space to those clusterings visited by the MCMC sampler. </li><li>A better method is the SALSO algorithm (<a href="#dahl">Dahl et al., 2022</a>), implemented in the <a href="https://www.r-project.org/">R</a> package <a href="https://CRAN.R-project.org/package=salso"><code>salso</code></a>, which heuristically searches the space of all possible clusterings.</li></ol><p>All of these methods are implemented in RedClust in the function <a href="reference/#RedClust.getpointestimate-Tuple{MCMCResult}"><code>getpointestimate</code></a>.</p><h2 id="Citing-this-package"><a class="docs-heading-anchor" href="#Citing-this-package">Citing this package</a><a id="Citing-this-package-1"></a><a class="docs-heading-anchor-permalink" href="#Citing-this-package" title="Permalink"></a></h2><p>If you want to use this package in your work, please cite it as:</p><p>Natarajan, A., De Iorio, M., Heinecke, A., Mayer, E. and Glenn, S., 2022. ‘Cohesion and Repulsion in Bayesian Distance Clustering’, arXiv <a href="https://arxiv.org/abs/2107.05414">2107.05414</a>.</p><h2 id="Bibliography"><a class="docs-heading-anchor" href="#Bibliography">Bibliography</a><a id="Bibliography-1"></a><a class="docs-heading-anchor-permalink" href="#Bibliography" title="Permalink"></a></h2><a id="betancourt"></a><p>Betancourt, B., Zanella, G. and Steorts, R. C. (2022), ‘Random partition models for microclustering tasks’, <em>Journal of the American Statistical Association</em> 117(539), 1215–1227. DOI: <a href="https://doi.org/10.1080/01621459.2020.1841647">10.1080/01621459.2020.1841647</a>.</p><a id="binder"></a><p>Binder, D. A. (1978). Bayesian Cluster Analysis. <em>Biometrika</em>, 65(1), 31–38. DOI: <a href="https://doi.org/10.2307/2335273">10.2307/2335273</a>.</p><a id="dahl"></a><p>Dahl, D. B., Johnson, D. J. and M¨uller, P. (2022), ‘Search algorithms and loss functions for Bayesian clustering’, <em>Journal of Computational and Graphical Statistics</em> 0(0), 1–13. DOI: <a href="https://doi.org/10.1080/10618600.2022.2069779">10.1080/10618600.2022.2069779</a>.</p><a id="kraskov"></a><p>Kraskov, A., Stögbauer, H., Andrzejak, R. G. and P Grassberger, P. (2005), ‘Hierarchical clustering using mutual information’, <em>Europhysics Letters (EPL)</em> 70(2), 278-284, DOI: <a href="https://doi.org/10.1209/epl/i2004-10483-y">10.1209/epl/i2004-10483-y</a>.</p><a id="meila"></a><p>Marina Meilă (2007), ‘Comparing clusterings—an information based distance’, <em>Journal of Multivariate Analysis</em>,  98(5), 873-895, DOI: <a href="https://doi.org/10.1016/j.jmva.2006.11.013">10.1016/j.jmva.2006.11.013</a>.</p><a id="miller"></a><p>Miller, J., Betancourt, B., Zaidi, A., Wallach, H. and Steorts, R. C. (2015), ‘Microclustering: When the cluster sizes grow sublinearly with the size of the data set’, arXiv <a href="https://arxiv.org/abs/1512.00792">1512.00792</a>.</p><a id="wade"></a><p>Wade, S. and Ghahramani, Z. (2018), ‘Bayesian Cluster Analysis: Point Estimation and Credible Balls (with Discussion)’, <em>Bayesian Analysis</em> 13(2), 559 – 626. DOI: <a href="https://doi.org/10.1214/17-BA1073">10.1214/17-BA1073</a>.</p></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="reference/">Reference »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Friday 14 October 2022 22:41">Friday 14 October 2022</span>. Using Julia version 1.7.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
